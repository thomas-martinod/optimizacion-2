{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "Find the absolute minimum of the function\n",
    "\n",
    "\\begin{equation}\n",
    "    f(x) = f(x_1, x_2) = x_1 e^{-{x_1}^2 -{x_2}^2}\n",
    "\\end{equation}\n",
    "\n",
    "in the domain $x \\in \\mathbb{R}^2$ (unconstrained problem).\n",
    "\n",
    "The initial point is $x^0 = (-0.6, -0.3)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized x1: -0.7071068193998944\n",
      "Optimized x2: -2.980431581506263e-37\n",
      "Optimized f(x): -0.42888194248035216\n",
      "\n",
      "Optimization Data:\n",
      "    Iteration        x1            x2      f(x)  |f(x_next) - f(x)|     β\n",
      "0           0 -0.600000 -3.000000e-01 -0.382577        3.825217e-01  0.01\n",
      "1           1 -0.600000 -3.000000e-01 -0.382577        3.274279e-01  0.10\n",
      "2           2 -0.600000 -3.000000e-01 -0.382577       -4.023621e-02  1.00\n",
      "3           3 -0.764615 -8.835218e-02 -0.422813        4.619382e-01  0.10\n",
      "4           4 -0.764615 -8.835218e-02 -0.422813       -4.923016e-03  1.00\n",
      "..        ...       ...           ...       ...                 ...   ...\n",
      "84         84 -0.707107 -1.473192e-35 -0.428882       -2.275957e-15  1.00\n",
      "85         85 -0.707107 -2.095411e-36 -0.428882        6.360468e-13  0.10\n",
      "86         86 -0.707107 -2.095411e-36 -0.428882       -1.221245e-15  1.00\n",
      "87         87 -0.707107 -2.980432e-37 -0.428882        3.256839e-13  0.10\n",
      "88         88 -0.707107 -2.980432e-37 -0.428882       -5.551115e-16  1.00\n",
      "\n",
      "[89 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the objective function f(x) that you want to minimize\n",
    "def f(x):\n",
    "    x1, x2 = x\n",
    "    return x1 * np.exp(-x1**2 - x2**2)\n",
    "\n",
    "# Define the Jacobian matrix (partial derivatives of f with respect to x1 and x2)\n",
    "def grad_f(x):\n",
    "    x1, x2 = x\n",
    "    df_dx1 = np.exp(-x1**2 - x2**2) - 2 * x1**2 * np.exp(-x1**2 - x2**2)\n",
    "    df_dx2 = -2 * x1 * x2 * np.exp(-x1**2 - x2**2)\n",
    "    return np.array([df_dx1, df_dx2])\n",
    "\n",
    "# Levenberg-Marquardt optimization with iteration data\n",
    "def levenberg_marquardt(x0, tol, J, beta_init):\n",
    "    x = np.array(x0)\n",
    "    β = beta_init\n",
    "    optimization_data = []\n",
    "    k = 0\n",
    "\n",
    "    while(True):\n",
    "        # Compute the gradient and Hessian (approximately the Jacobian)\n",
    "        g = -grad_f(x)\n",
    "        hessian = np.outer(g, g)\n",
    "        np.fill_diagonal(hessian, hessian.diagonal() + β)\n",
    "\n",
    "        # Compute the search direction using the pseudo-inverse\n",
    "        s = np.linalg.pinv(hessian).dot(g)\n",
    "\n",
    "        # Calculate the\n",
    "        fx = f(x)\n",
    "\n",
    "        # Update the parameter vector (λ = 1)\n",
    "        x_new = x + s\n",
    "\n",
    "        # Append data for this iteration\n",
    "        optimization_data.append({'Iteration': k, 'x1': x[0], 'x2': x[1], 'f(x)': fx, '|f(x_next) - f(x)|': f(x_new) - fx, 'β': β})\n",
    "\n",
    "        # Check for convergence based on gradient norm\n",
    "        if abs(f(x_new) - fx) < tol:\n",
    "            break\n",
    "\n",
    "        if k >= J:\n",
    "            break\n",
    "\n",
    "        # Update beta based on convergence\n",
    "        if f(x_new) < fx:\n",
    "            β /= 10\n",
    "            x = x_new\n",
    "        else:\n",
    "            β *= 10\n",
    "        k += 1\n",
    "\n",
    "    return x, optimization_data\n",
    "\n",
    "# Initial guess\n",
    "initial_guess = [-0.6, -0.3]\n",
    "\n",
    "# Set the tolerance for gradient norm\n",
    "tolerance = 1e-15\n",
    "\n",
    "# Perform LM optimization\n",
    "optimal_x, optimization_data = levenberg_marquardt(initial_guess, tol=tolerance, J=100, beta_init=0.01)\n",
    "\n",
    "# Create a Pandas DataFrame from the optimization data\n",
    "df = pd.DataFrame(optimization_data)\n",
    "\n",
    "# Print the results\n",
    "print(\"Optimized x1:\", optimal_x[0])\n",
    "print(\"Optimized x2:\", optimal_x[1])\n",
    "print(\"Optimized f(x):\", f(optimal_x))\n",
    "print(\"\\nOptimization Data:\")\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
